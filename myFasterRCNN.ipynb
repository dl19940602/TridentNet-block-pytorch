{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementation of trident block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trident_block(torch.nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, input_channels, output_channels, \n",
    "                 stride = 1, padding = [1,2,3], dilation = [1,2,3], downsample = None):\n",
    "        super(trident_block, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.downsample = downsample\n",
    "        \n",
    "        self.shared_weights4convolution1 = torch.nn.Parameter(torch.randn(input_channels,output_channels,1,1))\n",
    "        self.shared_weights4convolution2 = torch.nn.Parameter(torch.randn(output_channels,output_channels,3,3))\n",
    "        self.shared_weights4convolution3 = torch.nn.Parameter(torch.randn(output_channels,\n",
    "                                                                          output_channels*self.expansion,1,1))\n",
    "        self.bn11 = torch.nn.BatchNorm2d(output_channels)\n",
    "        self.bn12 = torch.nn.BatchNorm2d(output_channels)\n",
    "        self.bn13 = torch.nn.BatchNorm2d(output_channels*self.expansion)\n",
    "        \n",
    "        self.bn21 = torch.nn.BatchNorm2d(output_channels)\n",
    "        self.bn22 = torch.nn.BatchNorm2d(output_channels)\n",
    "        self.bn23 = torch.nn.BatchNorm2d(output_channels*self.expansion)\n",
    "        \n",
    "        self.bn31 = torch.nn.BatchNorm2d(output_channels)\n",
    "        self.bn32 = torch.nn.BatchNorm2d(output_channels)\n",
    "        self.bn33 = torch.nn.BatchNorm2d(output_channels*self.expansion)\n",
    "        \n",
    "        self.relu1 = torch.nn.ReLU(inplace = True)\n",
    "        self.relu2 = torch.nn.ReLU(inplace = True)\n",
    "        self.relu3 = torch.nn.ReLU(inplace = True)\n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def forward_branch_1(self,x): # bran\n",
    "        residual = x\n",
    "        # conv 1x1\n",
    "        output = torch.nn.functional.conv2d(x, shared_weights4convolution1, bias = None)\n",
    "        output = self.bn11(output)\n",
    "        output = self.relu1(output)\n",
    "        # conv 3x3\n",
    "        output = torch.nn.functional(output,self=shared_weights4convolution2, bias = None,\n",
    "                                    stride = self.stride, padding = self.padding[0], \n",
    "                                    dilation = self.dilation[0])\n",
    "        output = self.bn12(output)\n",
    "        output = self.relu1(output)\n",
    "        # conv 1x1\n",
    "        output = torch.nn.functional(output,shared_weights4convolution3,bias = None)\n",
    "        output = self.bn13(output)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = downsample(x)\n",
    "        \n",
    "        output += residual\n",
    "        output = self.relu1(output)\n",
    "        return output\n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def forward_branch_2(self,x): # bran\n",
    "        residual = x\n",
    "        # conv 1x1\n",
    "        output = torch.nn.functional.conv2d(x, shared_weights4convolution1, bias = None)\n",
    "        output = self.bn21(output)\n",
    "        output = self.relu2(output)\n",
    "        # conv 3x3\n",
    "        output = torch.nn.functional(output,self=shared_weights4convolution2, bias = None,\n",
    "                                    stride = self.stride, padding = self.padding[1], \n",
    "                                    dilation = self.dilation[1])\n",
    "        output = self.bn22(output)\n",
    "        output = self.relu2(output)\n",
    "        # conv 1x1\n",
    "        output = torch.nn.functional(output,shared_weights4convolution3,bias = None)\n",
    "        output = self.bn23(output)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = downsample(x)\n",
    "        \n",
    "        output += residual\n",
    "        output = self.relu2(output)\n",
    "        return output\n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def forward_branch_3(self,x): # bran\n",
    "        residual = x\n",
    "        # conv 1x1\n",
    "        output = torch.nn.functional.conv2d(x, shared_weights4convolution1, bias = None)\n",
    "        output = self.bn31(output)\n",
    "        output = self.relu3(output)\n",
    "        # conv 3x3\n",
    "        output = torch.nn.functional(output, self=shared_weights4convolution2, bias = None,\n",
    "                                    stride = self.stride, padding = self.padding[2], \n",
    "                                    dilation = self.dilation[2])\n",
    "        output = self.bn32(output)\n",
    "        output = self.relu3(output)\n",
    "        # conv 1x1\n",
    "        output = torch.nn.functional(output, shared_weights4convolution3, bias = None)\n",
    "        output = self.bn33(output)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = downsample(x)\n",
    "        \n",
    "        output += residual\n",
    "        output = self.relu3(output)\n",
    "        return output\n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def total_forward(self,x):\n",
    "        feature_list = list()\n",
    "        if self.downsample is not None:\n",
    "            feature_list.append(self.forward_branch_1(x))\n",
    "            feature_list.append(self.forward_branch_2(x))\n",
    "            feature_list.append(self.forward_branch_3(x))\n",
    "        else:\n",
    "            feature_list.append(self.forward_branch_1(x[0]))\n",
    "            feature_list.append(self.forward_branch_2(x[1]))\n",
    "            feature_list.append(self.forward_branch_3(x[2])) \n",
    "        return feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementation of BottleNeck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(torch.nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, input_channels, output_channels, downsample = None):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        # conv's structures\n",
    "        self.conv_1 = torch.nn.Conv2d(input_channels, output_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(output_channels)\n",
    "        \n",
    "        self.conv_2 = torch.nn.Conv2d(input_channels, output_channels, kernel_size=3, bias=False, padding = 1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(output_channels)\n",
    "        \n",
    "        self.conv_3 = torch.nn.Conv2d(input_channels, output_channels * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(output_channels * self.expansion)\n",
    "        \n",
    "        # acticvation and downsample\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        # conv 1x1\n",
    "        output = self.conv_1(x)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu(output)\n",
    "        # conv 3x3\n",
    "        output = self.conv_2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu(output)\n",
    "        # conv 1x1\n",
    "        output = self.conv_3(output)\n",
    "        output = self.bn3(output)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = downsample(x)\n",
    "        \n",
    "        output +=residual\n",
    "        output = self.relu(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementation of BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Basic_Block(torch.nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, downsample = None):\n",
    "        super(Basic_Block, self).__init__()\n",
    "        # conv's structures\n",
    "        self.conv1 = torch.nn.Conv2d(input_channels, output_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv2 = torch.nn.Conv2d(input_channels, output_channels, kernel_size=3, padding=1, bias=False)\n",
    "        # normalizations\n",
    "        self.bn1 = torch.nn.BatchNorm2d(output_channels)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(output_channels)\n",
    "        # acticvation and downsample\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        # first 3x3 convolution\n",
    "        output = self.conv1(x)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu(output)\n",
    "        # second 3x3 convolution\n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = downsample(x)\n",
    "        output += residual\n",
    "        output = self.relu(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, num_classes, net_type, BOT_block = BottleNeck, TRI_block = trident_block): \n",
    "        # ,\n",
    "        \"\"\"\n",
    "        params: avalible net_types - 'ResNet-50', \n",
    "                                     'ResNet-101', \n",
    "                                     'ResNet-152'\n",
    "        \"\"\"\n",
    "        self.input_channels = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.net_type = net_type\n",
    "        if self.net_type == 'ResNet-50':\n",
    "            print(\"Net_type is ResNet-50\")\n",
    "            layers = [3, 4, 6, 3]\n",
    "        if self.net_type == 'ResNet-101':\n",
    "            print(\"Net_type is ResNet-101\")\n",
    "            layers = [3, 4, 23, 3]\n",
    "        if self.net_type == 'ResNet-152':\n",
    "            print(\"Net_type is ResNet-152\")\n",
    "            layers = [3, 8, 36, 3]\n",
    "            \n",
    "        self.conv1 = torch.nn.Conv2d(3,64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1   = torch.nn.BatchNorm2d(64)\n",
    "        self.relu  = torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.max_pooling = torch.nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True) \n",
    "        \n",
    "        self.layer1 = self._make_layer(BOT_block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(BOT_block, 128, layers[1])    \n",
    "        self.layer3 = self._make_layer(BOT_block, 256, layers[2])\n",
    "        self.layer4 = self._make_layer(TRI_block, 512, layers[3])\n",
    "        \n",
    "        \n",
    "        self.avg_pool = torch.nn.AvgPool2d(kernel_size=7) # размерность та же \n",
    "        self.FC = torch.nn.Linear(512 * BOT_block.expansion, num_classes)\n",
    "        \n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def res_forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.max_pooling(output)\n",
    "        \n",
    "        output = self.layer1(output)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        output = self.layer4(output)\n",
    "\n",
    "        # Вопрос - что  елать с выхоом после Tridnt bлока\n",
    "        output = torch.cat([output[0],output[1],output[2]], dim = 0)\n",
    "        return output\n",
    "    \n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def _make_layer(self, block, output_channels, num_of_bottle_neck_blocks, stride = 1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.input_channels != output_channels*block.expansion:\n",
    "            downsample = torch.nn.Sequential(\n",
    "                                torch.nn.Conv2d(self.input_channels, output_channels * block.expansion,\n",
    "                                                kernel_size = 1, stride = stride, bias=False),\n",
    "                                torch.nn.BatchNorm2d(output_channels * block.expansion)\n",
    "            )\n",
    "        layers = list()\n",
    "        layers.append(block(self.input_channels, output_channels, downsample))\n",
    "        self.input_channels = output_channels * block.expansion\n",
    "        \n",
    "        for i in range(1,num_of_bottle_neck_blocks):\n",
    "            layers.append(block(self.input_channels,output_channels))\n",
    "            \n",
    "        return torch.nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/wllvcxz/faster-rcnn-pytorch/tree/master/model\n",
    "### https://github.com/jwyang/faster-rcnn.pytorch/blob/master/lib/model/rpn/rpn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = torch.randn(2,3,500,500)\n",
    "bbx = torch.randn(2,4)\n",
    "lbs = torch.tensor([[1.],\n",
    "                    [2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform()\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=21, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=84, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = torchvision.models.detection.fasterrcnn_resnet50_fpn(num_classes=21)\n",
    "model1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform()\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=21, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=84, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = torchvision.models.detection.fasterrcnn_resnet50_fpn(num_classes=21)\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def MultiBoxLoss(images, model):\n",
    "    # model = torchvision.models.detection.fasterrcnn_resnet50_fpn(num_classes=21)\n",
    "    transform1 = model.transform(images)[0]\n",
    "    transform2 = transform1.tensors\n",
    "    img_sizes = transform1.image_sizes\n",
    "    features1 = model.backbone(transform2)\n",
    "    # losses for RPN\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        images (ImageList): images for which we want to compute the predictions\n",
    "        features (List[Tensor]): features computed from the images that are\n",
    "            used for computing the predictions. Each tensor in the list\n",
    "            correspond to different feature levels\n",
    "        targets (List[Dict[Tensor]]): ground-truth boxes present in the image (optional).\n",
    "            If provided, each element in the dict should contain a field `boxes`,\n",
    "            with the locations of the ground-truth boxes.\n",
    "    Returns:\n",
    "        boxes (List[Tensor]): the predicted boxes from the RPN, one Tensor per\n",
    "            image.\n",
    "        losses (Dict[Tensor]): the losses for the model during training. During\n",
    "            testing, it is an empty dict.\n",
    "    \"\"\"\n",
    "\n",
    "    bboxes, rpn_losses = model.rpn.forward(transform1,features1)\n",
    "    try:\n",
    "        rpn_loss = rpn_losses['loss_objectness']+rpn_losses['loss_rpn_box_reg']\n",
    "    except:\n",
    "        rpn_loss = 'Not'\n",
    "        pass\n",
    "\n",
    "    # losses for RoI\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        features (List[Tensor])\n",
    "        proposals (List[Tensor[N, 4]])\n",
    "        image_shapes (List[Tuple[H, W]])\n",
    "        targets (List[Dict])\n",
    "    Returns:\n",
    "        classification_loss (Tensor)\n",
    "        box_loss (Tensor)\n",
    "    \"\"\"\n",
    "    result, roi_losses = model.roi_heads(features1, bboxes, img_sizes)\n",
    "    try:\n",
    "        roi_loss = roi_losses['loss_classifier']+roi_losses['loss_box_reg']\n",
    "    except:\n",
    "        roi_loss = ' ready'\n",
    "        pass\n",
    "\n",
    "    return rpn_loss+roi_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not ready'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiBoxLoss(images, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-09-11 13:20:55--  https://images.unsplash.com/photo-1458169495136-854e4c39548a\n",
      "Resolving localhost (localhost)... ::1, 127.0.0.1\n",
      "Connecting to localhost (localhost)|::1|:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 1168686 (1.1M) [image/jpeg]\n",
      "Saving to: ‘girl_cars.jpg’\n",
      "\n",
      "girl_cars.jpg       100%[===================>]   1.11M  3.44MB/s    in 0.3s    \n",
      "\n",
      "2019-09-11 13:20:56 (3.44 MB/s) - ‘girl_cars.jpg’ saved [1168686/1168686]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://images.unsplash.com/photo-1458169495136-854e4c39548a -O girl_cars.jpg\n",
    "#object_detection_api('./girl_cars.jpg', rect_th=15, text_th=7, text_size=5, threshold=0.8)  \n",
    "img = cv2.imread('./girl_cars.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_img = torch.tensor(img).permute(2,0,1).unsqueeze(0)\n",
    "tensor_bbox = torch.tensor([2300,600, 3500, 3300], dtype = torch.float64)\n",
    "tensor_label = torch.tensor([1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rez' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-dd2e6fec4616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrez\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthickness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthickness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rez' is not defined"
     ]
    }
   ],
   "source": [
    "pt1 = (2300,600) \n",
    "pt2 = (3500,3300)\n",
    "img2 = img.copy()\n",
    "for i in np.array(rez[0][:10]):\n",
    "    cv2.rectangle(img2, pt1,pt2, (255,0,0), thickness = 16)\n",
    "    cv2.rectangle(img2, (boxes[i][0],boxes[i][1]), (boxes[i][2],boxes[i][3]), color = (0,255,0), thickness = 16)\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "pt1 = (2300,600) \n",
    "pt2 = (3500,3300)\n",
    "pt = (pt1,pt2)\n",
    "bboxes = []\n",
    "img1 = img.copy()\n",
    "img1 = cv2.rectangle(img1, pt1,pt2, color = (255,0,0), thickness = 16)\n",
    "for proposals in range(100):\n",
    "    flag = random.choice([0,1])\n",
    "    if flag == 1:\n",
    "        x1 = pt[0][0]+random.randint(50, 500) \n",
    "        y1 = pt[0][1]+random.randint(50, 500)\n",
    "    else:\n",
    "        x1 = pt[0][0]-random.randint(50, 500) \n",
    "        y1 = pt[0][1]-random.randint(50, 500)\n",
    "\n",
    "    flag = random.choice([0,1])\n",
    "    if flag == 1:\n",
    "        x2 = pt[1][0]+random.randint(50, 500) \n",
    "        y2 = pt[1][1]+random.randint(50, 500)\n",
    "    else:    \n",
    "        x2 = pt[1][0]-random.randint(50, 500) \n",
    "        y2 = pt[1][1]-random.randint(50, 500)\n",
    "    \n",
    "    p11 = pt1\n",
    "    p12 = pt2\n",
    "    p21 = (x1,y1)\n",
    "    p22 = (x2,y2)\n",
    "    \n",
    "    xx1 = max(p11[0],p21[0])\n",
    "    yy1 = max(p11[1],p21[1])\n",
    "    xx2 = min(p12[0],p22[0])\n",
    "    yy2 = min(p12[1],p22[1])\n",
    "    w = xx2 - xx1\n",
    "    h = yy2 - yy1\n",
    "    square = w*h\n",
    "    union = (p12[0]-p11[0])*(p12[1]-p11[1]) + (p22[0]-p21[0])*(p22[1]-p21[1]) - square\n",
    "    iou = square/union    \n",
    "    \n",
    "    bboxes.append([[x1,y1, x2,y2], iou])\n",
    "    \n",
    "    cv2.rectangle(img1, (x1,y1), (x2,y2), color = (0,255,0), thickness = 16)\n",
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = []\n",
    "scores = []\n",
    "for el in bboxes:\n",
    "    boxes.append(el[0])\n",
    "    scores.append(el[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = torch.tensor(np.array(boxes), dtype = torch.float64)\n",
    "score = torch.tensor(np.array(scores), dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rez1 = torchvision.ops.nms(box, score, iou_threshold=0.5)\n",
    "rez1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
