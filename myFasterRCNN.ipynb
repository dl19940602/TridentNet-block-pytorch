{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8b1bf483ba434cb7059fd5273a08f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e224999b6ee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabelmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'background'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mima\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mimage_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mima\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0manno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mima\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/datasets/voc.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mXML\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \"\"\"\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         target = self.parse_voc_xml(\n\u001b[1;32m    199\u001b[0m             ET.parse(self.annotations[index]).getroot())\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    932\u001b[0m         \"\"\"\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_train = torchvision.datasets.VOCDetection(root = '../')\n",
    "image_list = list()\n",
    "annotation = list()\n",
    "labelmap = {'background':0}\n",
    "\n",
    "for i, ima in tqdm(enumerate(data_train)):\n",
    "    image_list.append(torch.tensor(np.array(ima[0])/255, dtype = torch.float32).permute(2,0,1))\n",
    "    anno = ima[1]['annotation']['object']\n",
    "    \n",
    "    \n",
    "    if isinstance(anno, type(list())):\n",
    "        box = []\n",
    "        label = []\n",
    "        for el in anno:\n",
    "            name = el['name']\n",
    "            if name not in labelmap.keys():\n",
    "                labelmap[name] = len(labelmap)\n",
    "            boxes = el['bndbox']\n",
    "\n",
    "            x1 = int(boxes['xmin'])\n",
    "            y1 = int(boxes['ymin'])\n",
    "            x2 = int(boxes['xmax'])\n",
    "            y2 = int(boxes['ymax'])\n",
    "            box.append([x1,y1,x2,y2])\n",
    "            label.append(labelmap[name])\n",
    "        annotation.append({'boxes':torch.tensor(np.array(box),dtype = torch.float), \n",
    "                           'labels':torch.tensor(label, dtype = torch.int64)})\n",
    "    else:\n",
    "\n",
    "        name = anno['name']\n",
    "        if name not in labelmap.keys():\n",
    "                labelmap[name] = len(labelmap)\n",
    "        boxes = el['bndbox']\n",
    "\n",
    "        x1 = int(boxes['xmin'])\n",
    "        y1 = int(boxes['ymin'])\n",
    "        x2 = int(boxes['xmax'])\n",
    "        y2 = int(boxes['ymax'])\n",
    "        t_box = torch.tensor([x1,y1,x2,y2],dtype = torch.float)\n",
    "        annotation.append({'boxes':t_box, 'labels':torch.tensor(labelmap[name], dtype = torch.int64)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(num_classes=21)\n",
    "lr = 1e-3\n",
    "\n",
    "biases = list()\n",
    "not_biases = list()\n",
    "for param_name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        if param_name.endswith('.bias'):\n",
    "            biases.append(param)\n",
    "        else:\n",
    "            not_biases.append(param)\n",
    "optimizer = torch.optim.SGD(params=[{'params': biases, 'lr': 2 * lr}, {'params': not_biases}],\n",
    "                            lr = lr)\n",
    "\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.7890, grad_fn=<AddBackward0>)\n",
      "tensor(15.7890, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "optimizer.zero_grad()\n",
    "im = image_list[:batch_size]\n",
    "#im = [i.to(device) for i in im]\n",
    "\n",
    "ann = annotation[:batch_size]\n",
    "#ann = [a.to(device) for a in ann]\n",
    "\n",
    "loss = model1(im,ann)\n",
    "\n",
    "los = loss['loss_classifier'] + loss['loss_box_reg']+loss['loss_objectness']+loss['loss_rpn_box_reg']\n",
    "print(los)\n",
    "los.backward()\n",
    "optimizer.step()\n",
    "print(los)\n",
    "\n",
    "del  im, ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[370 102 199 194]\n",
      "[253 299 115 348]\n",
      "[111 377 173  74]\n",
      "[223 140 251 351]\n",
      "[256 220 282 241]\n",
      "[ 33 232 382 314]\n",
      "[318 208 182 145]\n",
      "[284  94 368 161]\n",
      "[ 65 135 278 225]\n",
      "[ 25 276  27 312]\n",
      "[327 164 353  49]\n",
      "[387 356  34 151]\n",
      "[385 116 234  80]\n",
      "[133  29 383 118]\n",
      "[203 316 156 279]\n",
      "[275  99 190 237]\n",
      "[ 79 252 185  95]\n",
      "[265 165   3  96]\n",
      "[ 61  67 378 296]\n",
      "[ 39 100 374 221]\n",
      "[ 98 359 117 192]\n",
      "[300  66 283 142]\n",
      "[72 62 68  2]\n",
      "[335  85 109 184]\n",
      "[106 159  81 219]\n",
      "[244 309 201 291]\n",
      "[ 57 373  63 342]\n",
      "[366 122 288 240]\n",
      "[358  15 103 338]\n",
      "[343 238 138 207]\n",
      "[213 336 324 302]\n",
      "[149 152 372 153]\n",
      "[ 36 226 154  64]\n",
      "[304 320  73 139]\n",
      "[ 75 321  16 267]\n",
      "[ 91 301 379  71]\n",
      "[196  82 271 209]\n",
      "[187 242   6  83]\n",
      "[294 178  59 274]\n",
      "[ 76 295 339 216]\n",
      "[250 364 162 313]\n",
      "[371 322  19  58]\n",
      "[391 290 286 386]\n",
      "[ 84 132 168 375]\n",
      "[308  23 281  12]\n",
      "[155 248 350 389]\n",
      "[293 113  47 120]\n",
      "[  4 175 369   7]\n",
      "[243 334 130 229]\n",
      "[259  88 257  10]\n",
      "[235 150 224  56]\n",
      "[  1  24 315 108]\n",
      "[123  50 297 193]\n",
      "[124  78 171  69]\n",
      "[319 330 362 158]\n",
      "[298 129  21 354]\n",
      "[345 148 266  28]\n",
      "[217  35 212 200]\n",
      "[307 317  55 104]\n",
      "[110   5  44 349]\n",
      "[ 53 180 191  92]\n",
      "[255 264 143 170]\n",
      "[ 93 333  70  42]\n",
      "[177 141 380 134]\n",
      "[310 205 169  37]\n",
      "[157  13  97 126]\n",
      "[163 384 147 303]\n",
      "[325  48  26  30]\n",
      "[280 311 231  11]\n",
      "[166 337 246 114]\n",
      "[ 38 381 188 341]\n",
      "[365 174  77 160]\n",
      "[ 20  52  18 367]\n",
      "[247 144 228   9]\n",
      "[ 86 136 323 390]\n",
      "[329 105 206 210]\n",
      "[112 287 263 202]\n",
      "[121 376 249 360]\n",
      "[326 137 289  31]\n",
      "[236 233  17 128]\n",
      "[268 245 230 388]\n",
      "[347 222 198 328]\n",
      "[ 32 146 181 214]\n",
      "[179 189 239 107]\n",
      "[ 90 331 306 176]\n",
      "[ 43 167 127 292]\n",
      "[ 51 125   0 305]\n",
      "[285 172 211 204]\n",
      "[101 131 119 277]\n",
      "[186  87  14 352]\n",
      "[227 254 363  54]\n",
      "[269 260 272  45]\n",
      "[ 89 357 218 344]\n",
      "[355 332  60 215]\n",
      "[270 258 346  40]\n",
      "[ 22 197 340 195]\n",
      "[261   8 262 183]\n",
      "[273  41  46 361]\n",
      "[ 29  23 390   2]\n",
      "[ 40 140 205  69]\n",
      "[ 16  55 188 373]\n",
      "[ 37 213 166  42]\n",
      "[335 216 356 240]\n",
      "[353 289 304 254]\n",
      "[279 206 317 136]\n",
      "[195 372 119 106]\n",
      "[313 234 145 102]\n",
      "[326  45 375 153]\n",
      "[379 244  99  44]\n",
      "[167 369 191  57]\n",
      "[287  70 107 186]\n",
      "[229 238 114 176]\n",
      "[253  11  60 280]\n",
      "[218 208 325 343]\n",
      "[387  92 272 183]\n",
      "[ 34 257 262 212]\n",
      "[ 22 371 271  46]\n",
      "[ 17  77  25 131]\n",
      "[134  79 214 215]\n",
      "[ 28 197 116 189]\n",
      "[250 224 259 339]\n",
      "[105 221 312  74]\n",
      "[177 302 286 291]\n",
      "[ 41 260 367  48]\n",
      "[384 295 156 171]\n",
      "[169  35 370   5]\n",
      "[130 113 268 310]\n",
      "[315 334 359  97]\n",
      "[170 283  62  26]\n",
      "[300  31 308 108]\n",
      "[ 94   1 219 331]\n",
      "[154 336 285   9]\n",
      "[241 307 178 100]\n",
      "[227 380 187  87]\n",
      "[198 123 202 168]\n",
      "[306 133 143 179]\n",
      "[225 157 318 175]\n",
      "[248 110 120 128]\n",
      "[111 115  63 377]\n",
      "[249 363 163 348]\n",
      "[236 155 109 303]\n",
      "[152  86 124 290]\n",
      "[ 14  36  89 352]\n",
      "[ 78 122 330 146]\n",
      "[265   6 278 256]\n",
      "[160 355  20 193]\n",
      "[323 350 138 266]\n",
      "[ 30 246 118 150]\n",
      "[148 217  64  96]\n",
      "[267 251 158 211]\n",
      "[337  93 314 203]\n",
      "[347 296 273 135]\n",
      "[270 362 327 233]\n",
      "[ 47 358 293 368]\n",
      "[ 21 345 232  67]\n",
      "[139 366 185  51]\n",
      "[59 13 54 12]\n",
      "[ 88 184 354 376]\n",
      "[344  80 231 298]\n",
      "[342 112 222  18]\n",
      "[288 181  72  53]\n",
      "[242 275 360  24]\n",
      "[230 364 255 351]\n",
      "[126  82  58 319]\n",
      "[ 39  91 201 357]\n",
      "[ 83 385  38  49]\n",
      "[340 121 196 341]\n",
      "[ 65 194 382 220]\n",
      "[165 381  19 174]\n",
      "[ 81 321 235  56]\n",
      "[284 137 309 292]\n",
      "[383 305   4 117]\n",
      "[142 161 101 129]\n",
      "[332  73  32 378]\n",
      "[247 322 361 261]\n",
      "[333 299  50  98]\n",
      "[311 200 269 173]\n",
      "[324 228 258 192]\n",
      "[151  61   7 172]\n",
      "[329 204  75  95]\n",
      "[103   0 159 209]\n",
      "[190  84 263 389]\n",
      "[ 33 264  10  66]\n",
      "[243 164 127  85]\n",
      "[388  15 239 386]\n",
      "[149 199   8  90]\n",
      "[328 349 320 374]\n",
      "[162 301 338  71]\n",
      "[ 52 276  76 147]\n",
      "[223 125 365 252]\n",
      "[207  43 132 277]\n",
      "[104 282  27 316]\n",
      "[141 237 391 294]\n",
      "[226 245 210  68]\n",
      "[281 297 180 346]\n",
      "[274 144   3 182]\n",
      "[359 184 331 111]\n",
      "[ 20 317 193 156]\n",
      "[195 126 187 175]\n",
      "[191 347  61 104]\n",
      "[106  50 362 289]\n",
      "[339  75 228 114]\n",
      "[179 379 338 176]\n",
      "[ 56 278  67 170]\n",
      "[371 178 261 215]\n",
      "[ 59 232 310 110]\n",
      "[391 295 138 381]\n",
      "[198 157 150 131]\n",
      "[123  55 372 134]\n",
      "[117 206 355 258]\n",
      "[287 120 180 239]\n",
      "[208 304  82 382]\n",
      "[ 31 332 383 262]\n",
      "[ 76 231  65  29]\n",
      "[ 58  26 288 312]\n",
      "[389  97 122 165]\n",
      "[299 348 183 149]\n",
      "[384 281  64  80]\n",
      "[205 326  17  27]\n",
      "[148 222 390 349]\n",
      "[249 182 272 286]\n",
      "[227 217 273 224]\n",
      "[132 174 302  16]\n",
      "[341 113 297 277]\n",
      "[ 72  73 292 270]\n",
      "[356 268  28 330]\n",
      "[369 267 354 199]\n",
      "[ 46 188  98 167]\n",
      "[358  11 361 155]\n",
      "[ 93  52 213 260]\n",
      "[364 230 158 216]\n",
      "[328 265 380 212]\n",
      "[ 15 136 105  69]\n",
      "[378 186 342 309]\n",
      "[218 233  91 275]\n",
      "[324  53 142  99]\n",
      "[242 161 254 133]\n",
      "[252 335  88 343]\n",
      "[211 146   0  96]\n",
      "[  8 293  12 373]\n",
      "[255 344 314 385]\n",
      "[ 44 141  77 257]\n",
      "[ 92 319 325 246]\n",
      "[173  57 200  45]\n",
      "[204 189 316 162]\n",
      "[346 201  13 263]\n",
      "[ 49 313 320 388]\n",
      "[ 32 305 271  68]\n",
      "[160 298 370 374]\n",
      "[235  35 129 303]\n",
      "[  9 368 360 333]\n",
      "[ 81 291 107 300]\n",
      "[296  74   3 181]\n",
      "[340 318 247 238]\n",
      "[345 327 154 116]\n",
      "[177 243 164   5]\n",
      "[147 124 365 172]\n",
      "[209 128 241 274]\n",
      "[ 62 276  40 377]\n",
      "[ 33 282 166 301]\n",
      "[  2 197 118 386]\n",
      "[214 269 311 387]\n",
      "[202  94 190 152]\n",
      "[169  51  10 350]\n",
      "[283 171 121 321]\n",
      "[ 30  47 306 115]\n",
      "[203 234 248 109]\n",
      "[ 84 207  42  41]\n",
      "[  4 280  95 376]\n",
      "[144 130 367  36]\n",
      "[112  22 127  86]\n",
      "[250 357 308  60]\n",
      "[ 25  37  63 194]\n",
      "[  1  14  66 192]\n",
      "[322  23 221 223]\n",
      "[100 336 125 245]\n",
      "[135 229 151 185]\n",
      "[334 353 220 226]\n",
      "[ 21  89 279  43]\n",
      "[337 210   6 259]\n",
      "[375  19 237 251]\n",
      "[108  54  70 140]\n",
      "[284 266 315  78]\n",
      "[225 351 363 256]\n",
      "[159 366  71  48]\n",
      "[285 102  87 101]\n",
      "[290 119 196 236]\n",
      "[145  79 219  90]\n",
      "[240 103 168 352]\n",
      "[137 153  38 307]\n",
      "[ 34 244 323 143]\n",
      "[253 163 264   7]\n",
      "[ 24 139  85  18]\n",
      "[294 329  83  39]\n",
      "[249  42 175 341]\n",
      "[192 255 380 368]\n",
      "[ 82 276  37 314]\n",
      "[200 269  81  83]\n",
      "[239 109 287 275]\n",
      "[340 196  38 378]\n",
      "[145  58 234 346]\n",
      "[204 371 373 120]\n",
      "[167 320 227 248]\n",
      "[308 350 202 381]\n",
      "[156 198  92  90]\n",
      "[310 195  71 111]\n",
      "[176 127  76 361]\n",
      "[327  35 210 363]\n",
      "[184  80  45 383]\n",
      "[355 290 270  74]\n",
      "[121 306 133  49]\n",
      "[143 194 155  47]\n",
      "[311 235 178 216]\n",
      "[ 34 141 205 136]\n",
      "[137 334 330  96]\n",
      "[376 343 315 312]\n",
      "[174  13  31 171]\n",
      "[130 258  60  63]\n",
      "[ 62 353 217 180]\n",
      "[125  10 124 263]\n",
      "[ 97 331 181  32]\n",
      "[ 98 344  24 264]\n",
      "[128 244  52 309]\n",
      "[165 348 268  28]\n",
      "[366 112 279 115]\n",
      "[131  39  27   4]\n",
      "[162 226 271 251]\n",
      "[146 319 231 339]\n",
      "[ 79 243   0 142]\n",
      "[187 201 295  61]\n",
      "[110 186 118 318]\n",
      "[245  51 190 336]\n",
      "[384 379 179 357]\n",
      "[219   3  50 240]\n",
      "[273 139 375 265]\n",
      "[107 122  86 388]\n",
      "[325  40  29 387]\n",
      "[199  53 101 100]\n",
      "[324 301 300 218]\n",
      "[360 237 323 303]\n",
      "[247  12 206 372]\n",
      "[229  85  87 345]\n",
      "[67 56 30 72]\n",
      "[299  43  84 351]\n",
      "[ 59 349  26  99]\n",
      "[342 222  18 261]\n",
      "[221 374 246 286]\n",
      "[321 153 215   9]\n",
      "[391 335 102 267]\n",
      "[212 254 256 119]\n",
      "[164 329  89 213]\n",
      "[352 138 298 260]\n",
      "[193 225 135 294]\n",
      "[ 77 228 238 169]\n",
      "[277 386 197   1]\n",
      "[332 272   8 347]\n",
      "[189 104 223 140]\n",
      "[ 93   2 316 367]\n",
      "[356  11 281 257]\n",
      "[117 236 284  78]\n",
      "[365 220 302 214]\n",
      "[338 296 328 326]\n",
      "[ 88 250 283  21]\n",
      "[116  44  22  36]\n",
      "[297 322 163  75]\n",
      "[370   5 230 242]\n",
      "[159  19 282 203]\n",
      "[359 151 364  17]\n",
      "[333 106 168 337]\n",
      "[377  25 292 354]\n",
      "[ 70  64  95 317]\n",
      "[233 389 157 177]\n",
      "[278 291 285  73]\n",
      "[161 259 134 382]\n",
      "[ 20 149 253  68]\n",
      "[148 132 232 362]\n",
      "[224 358  33  54]\n",
      "[114 289 266 288]\n",
      "[ 46 144 123 113]\n",
      "[262  94  55 105]\n",
      "[129 160 252 191]\n",
      "[154 172 304  65]\n",
      "[ 66 147 188 183]\n",
      "[ 15 313 390  14]\n",
      "[307 173 152  69]\n",
      "[166 207 209  48]\n",
      "[150   6 208 385]\n",
      "[211  41 274  57]\n",
      "[369 158 305  23]\n",
      "[ 16 126 280 241]\n",
      "[ 91 108 182 103]\n",
      "[185   7 293 170]\n",
      "[293 303 223 389]\n",
      "[308 372 391  68]\n",
      "[201 193 287  72]\n",
      "[321 266 154  71]\n",
      "[351 224 334  93]\n",
      "[ 35 326 381 273]\n",
      "[143  37 163 134]\n",
      "[296 286 283  84]\n",
      "[311  22 270 359]\n",
      "[114 194 282 119]\n",
      "[290 343  77   3]\n",
      "[337 116  10 232]\n",
      "[  9 350  86 230]\n",
      "[382  26  18 139]\n",
      "[ 25 247 275 161]\n",
      "[ 58 251 156 363]\n",
      "[340  74 106  81]\n",
      "[ 65 225 258 210]\n",
      "[ 49 108 136 105]\n",
      "[101 204 325  54]\n",
      "[202 248 284 298]\n",
      "[118 347 128 380]\n",
      "[244 171 135 217]\n",
      "[216 318 387  92]\n",
      "[346  15 112 137]\n",
      "[212 162 376 172]\n",
      "[238 267 262 252]\n",
      "[164 368 124  60]\n",
      "[388 358 167  23]\n",
      "[360 180 140 254]\n",
      "[226  91 312 206]\n",
      "[377 331 310   7]\n",
      "[348 179 242 211]\n",
      "[362 327 147 361]\n",
      "[ 64 219  19  44]\n",
      "[329 131   5 150]\n",
      "[166  97  38 322]\n",
      "[ 56 203  29 370]\n",
      "[110 122  30 356]\n",
      "[  6 222 133  96]\n",
      "[305   4 178 366]\n",
      "[198 302 107 335]\n",
      "[301 330 385  43]\n",
      "[256  63  99 103]\n",
      "[264  36 373 149]\n",
      "[109  57 104 125]\n",
      "[221  27 183 336]\n",
      "[249 285 100 130]\n",
      "[ 94 158  48 306]\n",
      "[ 20 175   8 292]\n",
      "[129 191   1 200]\n",
      "[ 82 165 157  70]\n",
      "[260  98 231  73]\n",
      "[277  47 220  85]\n",
      "[344 126 234 379]\n",
      "[313 272  31  62]\n",
      "[153 269 145 209]\n",
      "[ 46 228 123 369]\n",
      "[317 295 240  66]\n",
      "[117 207 319 288]\n",
      "[386 235  69 261]\n",
      "[315 349 307  28]\n",
      "[333  90 345 341]\n",
      "[ 21  24 309 132]\n",
      "[314 159  67  12]\n",
      "[213 152 115 320]\n",
      "[229 297  42 208]\n",
      "[197 127 279 160]\n",
      "[390 375 181 332]\n",
      "[176  79 241 138]\n",
      "[263 243 364 146]\n",
      "[ 17 378  34  61]\n",
      "[148  13 236 182]\n",
      "[ 33  50 354 265]\n",
      "[ 76 367 205 233]\n",
      "[324  78 384 300]\n",
      "[ 52  51 355 174]\n",
      "[280 323   2 253]\n",
      "[ 41 111 259  53]\n",
      "[245  75 299  95]\n",
      "[294 169 188 237]\n",
      "[268 215 170  80]\n",
      "[328 276 218 374]\n",
      "[ 40  88 371 184]\n",
      "[173 365 189  11]\n",
      "[289  16 271 214]\n",
      "[102  59 142 120]\n",
      "[278 121  14 246]\n",
      "[338 186 177 257]\n",
      "[291  89 342  87]\n",
      "[144 274 353 339]\n",
      "[187 316 383 168]\n",
      "[250 195 192 141]\n",
      "[151 190 199  55]\n",
      "[357  83 155 113]\n",
      "[ 45  39 352 304]\n",
      "[ 32 185 281 255]\n",
      "[196 227   0 239]\n",
      "[102 273  25  58]\n",
      "[127 171 269  97]\n",
      "[211 249 212 144]\n",
      "[250 226  80 268]\n",
      "[119 301 349 118]\n",
      "[367 176  92 148]\n",
      "[113  72 332  18]\n",
      "[296 350 346 214]\n",
      "[324 343  99 348]\n",
      "[325 331 129   7]\n",
      "[303 255  69 314]\n",
      "[  6 370 321   5]\n",
      "[ 52 229 291  48]\n",
      "[136 238  81 388]\n",
      "[218 235 206 203]\n",
      "[151 274  43  28]\n",
      "[184  16 134 138]\n",
      "[160 217 295  75]\n",
      "[233  59 209 149]\n",
      "[239 116 328  35]\n",
      "[282 267 374  12]\n",
      "[ 29  37 133 109]\n",
      "[ 67 106 111  44]\n",
      "[ 47  15  65 260]\n",
      "[ 23  51  53 284]\n",
      "[ 66  26 222  86]\n",
      "[353 285 299 232]\n",
      "[271 225 201 316]\n",
      "[130  20 114 290]\n",
      "[376 132 262 358]\n",
      "[342 213 257  82]\n",
      "[197 219 369   0]\n",
      "[172 372 333 245]\n",
      "[190 194 205 355]\n",
      "[155 341 188  96]\n",
      "[ 93 221  76  39]\n",
      "[122 300 386 123]\n",
      "[ 55  31 310 391]\n",
      "[327 146 202 302]\n",
      "[ 30  22 334  34]\n",
      "[338 286  46 336]\n",
      "[256 266 263 317]\n",
      "[131  79 389 387]\n",
      "[165 377 318  13]\n",
      "[385  14  85  64]\n",
      "[187 365 179  88]\n",
      "[  4 137  95 344]\n",
      "[311 315 104 191]\n",
      "[ 42  11  49 361]\n",
      "[124 115 150 110]\n",
      "[368  89 289  33]\n",
      "[175  10 112 126]\n",
      "[320 140 352  74]\n",
      "[330 156  70 223]\n",
      "[143 208 195 227]\n",
      "[204 207 258 181]\n",
      "[ 87  71 224 147]\n",
      "[142 164 186  62]\n",
      "[108 304 264  77]\n",
      "[347 244 354 237]\n",
      "[326 270 107 381]\n",
      "[335 351 371  36]\n",
      "[ 50 253  45 293]\n",
      "[248  56 196 228]\n",
      "[279 339 345 242]\n",
      "[192 375 298 173]\n",
      "[329 294 145 337]\n",
      "[183 272 357 359]\n",
      "[254 313 216 101]\n",
      "[ 32 307 103 167]\n",
      "[ 73 280   9 139]\n",
      "[340  54 390 154]\n",
      "[210 373  24  91]\n",
      "[ 78   8 168  40]\n",
      "[ 68 247  83 323]\n",
      "[265 128 246 309]\n",
      "[364  94 288 322]\n",
      "[117 383 200 157]\n",
      "[287  57  63 278]\n",
      "[ 84 199  38 166]\n",
      "[241 297   2 169]\n",
      "[158 161 152 308]\n",
      "[379  98  17 230]\n",
      "[305 141 259 240]\n",
      "[120 220   1   3]\n",
      "[177 261  41 243]\n",
      "[366 180  27 236]\n",
      "[193 162 178 185]\n",
      "[292 100 174 356]\n",
      "[281 182 163 252]\n",
      "[215 380 234 363]\n",
      "[ 19 283 231  90]\n",
      "[135 125 382 121]\n",
      "[ 60 276 277 105]\n",
      "[170 360  21 362]\n",
      "[319 384  61 306]\n",
      "[153 159 378 275]\n",
      "[198 251 312 189]\n",
      "[177 281 179 367]\n",
      "[118 154 124 119]\n",
      "[ 82 158 268 286]\n",
      "[251 250 209 343]\n",
      "[369 293 161 319]\n",
      "[306 260  36 247]\n",
      "[376 148 127 153]\n",
      "[135 165 377  56]\n",
      "[134   1 259  75]\n",
      "[123  77 290  73]\n",
      "[324 314  58 296]\n",
      "[173 159 370 131]\n",
      "[166 218 266 385]\n",
      "[238  39  52 200]\n",
      "[269 236  99  66]\n",
      "[ 95 112 208  55]\n",
      "[ 80 160 205 246]\n",
      "[138 305  15 220]\n",
      "[334 113 267 115]\n",
      "[104 280 300 170]\n",
      "[101 169  64 371]\n",
      "[327 106   2 349]\n",
      "[381 212 387  44]\n",
      "[331 390 323  69]\n",
      "[182 256  38  16]\n",
      "[ 32 180 264 105]\n",
      "[227 164  11 271]\n",
      "[261 126 310  83]\n",
      "[174  41  94 340]\n",
      "[199  57 277   5]\n",
      "[302 341 129 389]\n",
      "[202  30 147   6]\n",
      "[301 219  97 189]\n",
      "[248  17 229 243]\n",
      "[383 186  35  46]\n",
      "[196  20 348 358]\n",
      "[ 87 372  26  72]\n",
      "[ 93   9 211  19]\n",
      "[357 111   8 117]\n",
      "[232  37  48  43]\n",
      "[333 114 338 210]\n",
      "[282   3 141  33]\n",
      "[292 192 176 365]\n",
      "[373 356 254 350]\n",
      "[ 78 207 194 313]\n",
      "[178 355 309 201]\n",
      "[ 84 270 364 239]\n",
      "[295 375 142  29]\n",
      "[335 168 317 245]\n",
      "[241  85 175 193]\n",
      "[ 65 255 185 361]\n",
      "[102 231 150 362]\n",
      "[253 307 140 171]\n",
      "[ 91 215 336  45]\n",
      "[190 352 325 272]\n",
      "[ 24 223  23 382]\n",
      "[353  12 359 146]\n",
      "[ 47  51  34 316]\n",
      "[233 252 288 191]\n",
      "[230 318 203 315]\n",
      "[354  90 188 265]\n",
      "[155 346  63 312]\n",
      "[368 249 298 224]\n",
      "[263 100 163  54]\n",
      "[283 195 278 258]\n",
      "[380 198 275  71]\n",
      "[216 121 136 222]\n",
      "[151 337  81  61]\n",
      "[130 162 379 107]\n",
      "[206  89  68  25]\n",
      "[360  88 152 257]\n",
      "[291 308 262 320]\n",
      "[110 167 287 242]\n",
      "[122 157  22 226]\n",
      "[  0 120 204 297]\n",
      "[214 221 303  70]\n",
      "[ 62 284 108  60]\n",
      "[235 143 137 244]\n",
      "[228 299  13 144]\n",
      "[ 74 187  59 285]\n",
      "[  4  79 294 279]\n",
      "[339 363 213 351]\n",
      "[328  27 125 145]\n",
      "[237 342  67 109]\n",
      "[388 133 321  18]\n",
      "[ 10 132 197 347]\n",
      "[322 391 345 183]\n",
      "[149 172 304 217]\n",
      "[ 40  92  50 374]\n",
      "[181  14 273  53]\n",
      "[344 234 326 184]\n",
      "[ 86   7  76 366]\n",
      "[116  98 378  49]\n",
      "[42 96 31 21]\n",
      "[386 274 225 156]\n",
      "[384 311 139 329]\n",
      "[128 289 103 330]\n",
      "[ 28 240 332 276]\n",
      "[113  28 347 295]\n",
      "[285  51 214  68]\n",
      "[390 331 169 308]\n",
      "[  0 302 293 203]\n",
      "[ 19 140 147 146]\n",
      "[312 101 125 383]\n",
      "[269  96 131  52]\n",
      "[ 89 243 336 368]\n",
      "[ 24  69 379 257]\n",
      "[377 128 315 176]\n",
      "[209 249 276 309]\n",
      "[ 49 332 118 107]\n",
      "[317 286 292 100]\n",
      "[199 375 111  11]\n",
      "[298   9 229 263]\n",
      "[352 194 323 106]\n",
      "[378 121 144 156]\n",
      "[ 74 346 385 321]\n",
      "[362 339 206  55]\n",
      "[196 191   5  63]\n",
      "[320  46 306 216]\n",
      "[384 228 192 248]\n",
      "[ 29  15 318 162]\n",
      "[353 189 360 326]\n",
      "[ 95 116   7 255]\n",
      "[184 139 250 319]\n",
      "[281  14  12  16]\n",
      "[142 183 270 345]\n",
      "[220  90  54 181]\n",
      "[ 94 288  37 373]\n",
      "[386 149 357 205]\n",
      "[ 23 343 361 155]\n",
      "[389 246 164 231]\n",
      "[178 222 237 372]\n",
      "[ 18 344  44 335]\n",
      "[316  33  99  40]\n",
      "[ 66 198 338 148]\n",
      "[340 274 154  84]\n",
      "[381 283 333  41]\n",
      "[380 387 370 260]\n",
      "[ 64 280 166 110]\n",
      "[272 145 239 177]\n",
      "[279  39 109 112]\n",
      "[ 27 103 391 160]\n",
      "[204  10 185  93]\n",
      "[105 137 182 322]\n",
      "[241 359 266 190]\n",
      "[264  36 232 217]\n",
      "[219  75 115 114]\n",
      "[230 356 151 123]\n",
      "[172  88  32 108]\n",
      "[376  13 212 303]\n",
      "[348  42   2   6]\n",
      "[ 20  48 117 310]\n",
      "[157  98  76 284]\n",
      "[ 57 215 180 245]\n",
      "[351  78  61 158]\n",
      "[325 141  62 311]\n",
      "[374 197 277 334]\n",
      "[296 233 187 226]\n",
      "[349  80  83  81]\n",
      "[ 77 268  92  47]\n",
      "[104  60 369  43]\n",
      "[ 45  35  86 252]\n",
      "[168  91 275 350]\n",
      "[354 265 130   4]\n",
      "[365  21 261 253]\n",
      "[254 152 202  70]\n",
      "[341 244 195 297]\n",
      "[136 143 126  73]\n",
      "[290 120  67  72]\n",
      "[ 53  65 223  82]\n",
      "[127 305 324 135]\n",
      "[236 124 301 208]\n",
      "[ 17 259 224 337]\n",
      "[299 273 238 153]\n",
      "[278 122 242 138]\n",
      "[300 240   3 201]\n",
      "[221 159 235  79]\n",
      "[267 165 328 271]\n",
      "[ 34 218 173 366]\n",
      "[  8 132 342  30]\n",
      "[287 129  59  97]\n",
      "[207 256 186  85]\n",
      "[291  58 388 188]\n",
      "[119 174 133 258]\n",
      "[251  50 307 294]\n",
      "[364 247  71 210]\n",
      "[170 150 304 134]\n",
      "[161 262 371  87]\n",
      "[327  56 382 330]\n",
      "[314 363  31 179]\n",
      "[ 26   1 167 367]\n",
      "[282 227 358 313]\n",
      "[225 355 193 171]\n",
      "[211 289 102  22]\n",
      "[175 163  38 200]\n",
      "[329 234 213  25]\n",
      "[239 300 188 134]\n",
      "[ 30 356 167 295]\n",
      "[ 14 284 181   8]\n",
      "[324 382 373 279]\n",
      "[227 299 234 154]\n",
      "[206 348 145 194]\n",
      "[313  46 176 304]\n",
      "[322  29 220 183]\n",
      "[389 331 287 242]\n",
      "[371 213 298 359]\n",
      "[ 80   3 143 257]\n",
      "[ 10  18 325 135]\n",
      "[117 289 352  84]\n",
      "[127 196 367 285]\n",
      "[  2  20 112 248]\n",
      "[209   4 290  91]\n",
      "[264   1 375 171]\n",
      "[166 182  51  28]\n",
      "[157 243  82 388]\n",
      "[365 146 321  50]\n",
      "[333 307 207 110]\n",
      "[172 354 310 360]\n",
      "[327 195  94  44]\n",
      "[386 258 102 152]\n",
      "[320 173 376 379]\n",
      "[ 52 214 118  21]\n",
      "[158 100 336 391]\n",
      "[342 215 269 216]\n",
      "[ 35  75 370 125]\n",
      "[249 267  68 256]\n",
      "[ 77 378 178 177]\n",
      "[ 90 318 164  62]\n",
      "[179 129 291  72]\n",
      "[270 187 381 180]\n",
      "[261 223  27  24]\n",
      "[272  37 150  59]\n",
      "[109 294 262 185]\n",
      "[293 369  66 201]\n",
      "[238  73  57  87]\n",
      "[271 205 302 250]\n",
      "[268  99 314 126]\n",
      "[ 40  36 148 105]\n",
      "[ 81 337 101 139]\n",
      "[357 198 142  19]\n",
      "[280 193 259 184]\n",
      "[283   9  61 341]\n",
      "[111 350 241 346]\n",
      "[133 131  79 199]\n",
      "[ 48 374 335  85]\n",
      "[ 49 362  23 347]\n",
      "[332  11 383 323]\n",
      "[ 71 121 277 221]\n",
      "[ 53 344  56 165]\n",
      "[ 67 159 372 230]\n",
      "[384 266 339 273]\n",
      "[156 387 368 161]\n",
      "[278 275 225 115]\n",
      "[ 15 122 226 297]\n",
      "[212  38  78 345]\n",
      "[263 246 303 217]\n",
      "[282 113 119 116]\n",
      "[208  17 123   5]\n",
      "[292 104  12 197]\n",
      "[235 334 301  65]\n",
      "[153 329  92 286]\n",
      "[130 338 358  54]\n",
      "[204  88 385 228]\n",
      "[315 138 351 120]\n",
      "[86 58 32  0]\n",
      "[ 33 162 328 211]\n",
      "[ 93 170 364 151]\n",
      "[340 274 240 305]\n",
      "[236  22 224 174]\n",
      "[141  25 296 380]\n",
      "[ 34 210 316 163]\n",
      "[276 190 377 288]\n",
      "[189 149 252  41]\n",
      "[309 306 114 186]\n",
      "[ 64  74 255 260]\n",
      "[319   7  31  39]\n",
      "[ 89 245 140 311]\n",
      "[219 137 107 200]\n",
      "[254 312 144  26]\n",
      "[203 169  47 349]\n",
      "[  6 237  42  60]\n",
      "[326 132 251 103]\n",
      "[247 160 147 281]\n",
      "[265 317 366  76]\n",
      "[ 83 390 355 192]\n",
      "[ 96 231 108  63]\n",
      "[218 106 330  55]\n",
      "[232  97  69 353]\n",
      "[ 70  13 233 244]\n",
      "[175 191 343 229]\n",
      "[222 253 363  45]\n",
      "[202 308 155 124]\n",
      "[ 43 136 361 168]\n",
      "[128  16  95  98]\n",
      "[270 343   9 337]\n",
      "[ 40 245 295 162]\n",
      "[259 354 216  93]\n",
      "[ 97 145 249  65]\n",
      "[319 334 383 286]\n",
      "[250 268 116 214]\n",
      "[184 384 339 205]\n",
      "[208  73 335 159]\n",
      "[330 248  21   5]\n",
      "[ 67 180   7 340]\n",
      "[147 301  88 387]\n",
      "[179  76  23 325]\n",
      "[ 15 217 149 321]\n",
      "[331 244 308   3]\n",
      "[194 158 242 154]\n",
      "[  0 344 195 139]\n",
      "[ 36 247 262 388]\n",
      "[376  75  43 316]\n",
      "[336 389 305  58]\n",
      "[ 59 257  95 265]\n",
      "[153  83  52 367]\n",
      "[278 352 269 346]\n",
      "[ 13 134 182 238]\n",
      "[ 77 304 142  60]\n",
      "[280 120 266 370]\n",
      "[ 99 348 181  96]\n",
      "[ 44 292 164 143]\n",
      "[211 287  17 144]\n",
      "[161 358  26 327]\n",
      "[105 275 322 124]\n",
      "[279  57 375  22]\n",
      "[ 71  68  34 226]\n",
      "[307  80 360 377]\n",
      "[ 87 199 240 299]\n",
      "[243 366  66  54]\n",
      "[171 294 106 273]\n",
      "[ 61 312 256 329]\n",
      "[303  14 230 117]\n",
      "[277  37 374 126]\n",
      "[378 274 263 318]\n",
      "[187  32 246  31]\n",
      "[ 29 221  62 260]\n",
      "[229 302 190 189]\n",
      "[ 90 140  94  11]\n",
      "[283 320 386 215]\n",
      "[183  84 170 293]\n",
      "[ 35 296 379  45]\n",
      "[300 359  72 368]\n",
      "[203  70 156 167]\n",
      "[ 24 267 220 233]\n",
      "[219 122 282 356]\n",
      "[115 227 255  98]\n",
      "[174 298 261 363]\n",
      "[213  20 197 309]\n",
      "[178  51 100 357]\n",
      "[ 28 355  78 391]\n",
      "[206 239 141 135]\n",
      "[237 137 173  12]\n",
      "[253  18 258 380]\n",
      "[ 25 323 341 191]\n",
      "[324  10 315   1]\n",
      "[ 85 200  86 209]\n",
      "[284 188 110 192]\n",
      "[328 326 150 121]\n",
      "[332 138 118 196]\n",
      "[  4 125  30   8]\n",
      "[333 130 222 119]\n",
      "[390 264 349 155]\n",
      "[364  46  82 231]\n",
      "[224 317  33 350]\n",
      "[365 241 109 132]\n",
      "[210 163 385 129]\n",
      "[165 133 113  92]\n",
      "[112 127 232 175]\n",
      "[108 225  89  19]\n",
      "[236 172 136 345]\n",
      "[ 53 146 201 276]\n",
      "[290 218 207 152]\n",
      "[289 166 291 310]\n",
      "[ 16 306 347 362]\n",
      "[111 176  74 128]\n",
      "[177 204 123 114]\n",
      "[297 372 107 202]\n",
      "[ 79 272   6  49]\n",
      "[ 27 234  42 235]\n",
      "[ 64 186  55 381]\n",
      "[103 251 228 157]\n",
      "[271  50 281  39]\n",
      "[102  63 131 198]\n",
      "[254 160 288 223]\n",
      "[342  69  91  47]\n",
      "[371  81 151 185]\n",
      "[ 48 169 101  41]\n",
      "[369 382  38 353]\n",
      "[373 314  56 351]\n",
      "[361 338 193 252]\n",
      "[212 311 148 313]\n",
      "[285 168   2 104]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 4\n",
    "lr = 1e-3\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(num_classes=21)\n",
    "biases = list()\n",
    "not_biases = list()\n",
    "for param_name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        if param_name.endswith('.bias'):\n",
    "            biases.append(param)\n",
    "        else:\n",
    "            not_biases.append(param)\n",
    "optimizer = torch.optim.SGD(params=[{'params': biases, 'lr': lr}, {'params': not_biases}],\n",
    "                            lr = lr)\n",
    "\n",
    "    \n",
    "for epoch in range(n_epochs):\n",
    "    order = np.random.permutation(len(image_list))\n",
    "    \n",
    "    for start_index in range(0, len(image_list), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        batch_indexes = order[start_index:start_index+batch_size]\n",
    "        \n",
    "        #print(batch_indexes)\n",
    "        \n",
    "#         X_batch = image_list[batch_indexes] #.to(device)\n",
    "#         y_batch = annotation[batch_indexes] #.to(device)\n",
    "        \n",
    "#         loss = model(X_batch, y_batch) \n",
    "#         los = loss['loss_classifier'] + loss['loss_box_reg']+loss['loss_objectness']+loss['loss_rpn_box_reg']\n",
    "#         los.backward()\n",
    "#         optimizer.step()\n",
    "#         print(los)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        \n",
    "# ====================\n",
    "def MultiBoxLoss(images, model):\n",
    "    # model = torchvision.models.detection.fasterrcnn_resnet50_fpn(num_classes=21)\n",
    "    transform1 = model.transform(images)[0]\n",
    "    transform2 = transform1.tensors\n",
    "    img_sizes = transform1.image_sizes\n",
    "    features1 = model.backbone(transform2)\n",
    "    # losses for RPN\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        images (ImageList): images for which we want to compute the predictions\n",
    "        features (List[Tensor]): features computed from the images that are\n",
    "            used for computing the predictions. Each tensor in the list\n",
    "            correspond to different feature levels\n",
    "        targets (List[Dict[Tensor]]): ground-truth boxes present in the image (optional).\n",
    "            If provided, each element in the dict should contain a field `boxes`,\n",
    "            with the locations of the ground-truth boxes.\n",
    "    Returns:\n",
    "        boxes (List[Tensor]): the predicted boxes from the RPN, one Tensor per\n",
    "            image.\n",
    "        losses (Dict[Tensor]): the losses for the model during training. During\n",
    "            testing, it is an empty dict.\n",
    "    \"\"\"\n",
    "\n",
    "    bboxes, rpn_losses = model.rpn.forward(transform1,features1) # + targets\n",
    "    try:\n",
    "        rpn_loss = rpn_losses['loss_objectness']+rpn_losses['loss_rpn_box_reg']\n",
    "    except:\n",
    "        rpn_loss = 'Not'\n",
    "        pass\n",
    "\n",
    "    # losses for RoI\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        features (List[Tensor])\n",
    "        proposals (List[Tensor[N, 4]])\n",
    "        image_shapes (List[Tuple[H, W]])\n",
    "        targets (List[Dict])\n",
    "    Returns:\n",
    "        classification_loss (Tensor)\n",
    "        box_loss (Tensor)\n",
    "    \"\"\"\n",
    "    result, roi_losses = model.roi_heads(features1, bboxes, img_sizes) # + targets \n",
    "    try:\n",
    "        roi_loss = roi_losses['loss_classifier']+roi_losses['loss_box_reg']\n",
    "    except:\n",
    "        roi_loss = ' ready'\n",
    "        pass\n",
    "\n",
    "    return rpn_loss+roi_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementation of trident block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trident_block(torch.nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, input_channels, output_channels, \n",
    "                 stride = 1, padding = [1,2,3], dilation = [1,2,3], downsample = None):\n",
    "        super(trident_block, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.downsample = downsample\n",
    "        \n",
    "        self.shared_weights4convolution1 = torch.nn.Parameter(torch.randn(input_channels,output_channels,1,1))\n",
    "        self.shared_weights4convolution2 = torch.nn.Parameter(torch.randn(output_channels,output_channels,3,3))\n",
    "        self.shared_weights4convolution3 = torch.nn.Parameter(torch.randn(output_channels,\n",
    "                                                                          output_channels*self.expansion,1,1))\n",
    "        self.bn11 = torch.nn.BatchNorm2d(output_channels)\n",
    "        self.bn12 = torch.nn.BatchNorm2d(output_channels)\n",
    "        self.bn13 = torch.nn.BatchNorm2d(output_channels*self.expansion)\n",
    "        \n",
    "        self.bn21 = torch.nn.BatchNorm2d(output_channels)\n",
    "        self.bn22 = torch.nn.BatchNorm2d(output_channels)\n",
    "        self.bn23 = torch.nn.BatchNorm2d(output_channels*self.expansion)\n",
    "        \n",
    "        self.bn31 = torch.nn.BatchNorm2d(output_channels)\n",
    "        self.bn32 = torch.nn.BatchNorm2d(output_channels)\n",
    "        self.bn33 = torch.nn.BatchNorm2d(output_channels*self.expansion)\n",
    "        \n",
    "        self.relu1 = torch.nn.ReLU(inplace = True)\n",
    "        self.relu2 = torch.nn.ReLU(inplace = True)\n",
    "        self.relu3 = torch.nn.ReLU(inplace = True)\n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def forward_branch_1(self,x): # bran\n",
    "        residual = x\n",
    "        # conv 1x1\n",
    "        output = torch.nn.functional.conv2d(x, shared_weights4convolution1, bias = None)\n",
    "        output = self.bn11(output)\n",
    "        output = self.relu1(output)\n",
    "        # conv 3x3\n",
    "        output = torch.nn.functional(output,self=shared_weights4convolution2, bias = None,\n",
    "                                    stride = self.stride, padding = self.padding[0], \n",
    "                                    dilation = self.dilation[0])\n",
    "        output = self.bn12(output)\n",
    "        output = self.relu1(output)\n",
    "        # conv 1x1\n",
    "        output = torch.nn.functional(output,shared_weights4convolution3,bias = None)\n",
    "        output = self.bn13(output)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = downsample(x)\n",
    "        \n",
    "        output += residual\n",
    "        output = self.relu1(output)\n",
    "        return output\n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def forward_branch_2(self,x): # bran\n",
    "        residual = x\n",
    "        # conv 1x1\n",
    "        output = torch.nn.functional.conv2d(x, shared_weights4convolution1, bias = None)\n",
    "        output = self.bn21(output)\n",
    "        output = self.relu2(output)\n",
    "        # conv 3x3\n",
    "        output = torch.nn.functional(output,self=shared_weights4convolution2, bias = None,\n",
    "                                    stride = self.stride, padding = self.padding[1], \n",
    "                                    dilation = self.dilation[1])\n",
    "        output = self.bn22(output)\n",
    "        output = self.relu2(output)\n",
    "        # conv 1x1\n",
    "        output = torch.nn.functional(output,shared_weights4convolution3,bias = None)\n",
    "        output = self.bn23(output)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = downsample(x)\n",
    "        \n",
    "        output += residual\n",
    "        output = self.relu2(output)\n",
    "        return output\n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def forward_branch_3(self,x): # bran\n",
    "        residual = x\n",
    "        # conv 1x1\n",
    "        output = torch.nn.functional.conv2d(x, shared_weights4convolution1, bias = None)\n",
    "        output = self.bn31(output)\n",
    "        output = self.relu3(output)\n",
    "        # conv 3x3\n",
    "        output = torch.nn.functional(output, self=shared_weights4convolution2, bias = None,\n",
    "                                    stride = self.stride, padding = self.padding[2], \n",
    "                                    dilation = self.dilation[2])\n",
    "        output = self.bn32(output)\n",
    "        output = self.relu3(output)\n",
    "        # conv 1x1\n",
    "        output = torch.nn.functional(output, shared_weights4convolution3, bias = None)\n",
    "        output = self.bn33(output)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = downsample(x)\n",
    "        \n",
    "        output += residual\n",
    "        output = self.relu3(output)\n",
    "        return output\n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def total_forward(self,x):\n",
    "        feature_list = list()\n",
    "        if self.downsample is not None:\n",
    "            feature_list.append(self.forward_branch_1(x))\n",
    "            feature_list.append(self.forward_branch_2(x))\n",
    "            feature_list.append(self.forward_branch_3(x))\n",
    "        else:\n",
    "            feature_list.append(self.forward_branch_1(x[0]))\n",
    "            feature_list.append(self.forward_branch_2(x[1]))\n",
    "            feature_list.append(self.forward_branch_3(x[2])) \n",
    "        return feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementation of BottleNeck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(torch.nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, input_channels, output_channels, downsample = None):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        # conv's structures\n",
    "        self.conv_1 = torch.nn.Conv2d(input_channels, output_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(output_channels)\n",
    "        \n",
    "        self.conv_2 = torch.nn.Conv2d(input_channels, output_channels, kernel_size=3, bias=False, padding = 1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(output_channels)\n",
    "        \n",
    "        self.conv_3 = torch.nn.Conv2d(input_channels, output_channels * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(output_channels * self.expansion)\n",
    "        \n",
    "        # acticvation and downsample\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        # conv 1x1\n",
    "        output = self.conv_1(x)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu(output)\n",
    "        # conv 3x3\n",
    "        output = self.conv_2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu(output)\n",
    "        # conv 1x1\n",
    "        output = self.conv_3(output)\n",
    "        output = self.bn3(output)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = downsample(x)\n",
    "        \n",
    "        output +=residual\n",
    "        output = self.relu(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementation of BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Basic_Block(torch.nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, downsample = None):\n",
    "        super(Basic_Block, self).__init__()\n",
    "        # conv's structures\n",
    "        self.conv1 = torch.nn.Conv2d(input_channels, output_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.conv2 = torch.nn.Conv2d(input_channels, output_channels, kernel_size=3, padding=1, bias=False)\n",
    "        # normalizations\n",
    "        self.bn1 = torch.nn.BatchNorm2d(output_channels)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(output_channels)\n",
    "        # acticvation and downsample\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        # first 3x3 convolution\n",
    "        output = self.conv1(x)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu(output)\n",
    "        # second 3x3 convolution\n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = downsample(x)\n",
    "        output += residual\n",
    "        output = self.relu(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of ResNet Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, num_classes, net_type, BOT_block = BottleNeck, TRI_block = trident_block): \n",
    "        # ,\n",
    "        \"\"\"\n",
    "        params: avalible net_types - 'ResNet-50', \n",
    "                                     'ResNet-101', \n",
    "                                     'ResNet-152'\n",
    "        \"\"\"\n",
    "        self.input_channels = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.net_type = net_type\n",
    "        if self.net_type == 'ResNet-50':\n",
    "            print(\"Net_type is ResNet-50\")\n",
    "            layers = [3, 4, 6, 3]\n",
    "        if self.net_type == 'ResNet-101':\n",
    "            print(\"Net_type is ResNet-101\")\n",
    "            layers = [3, 4, 23, 3]\n",
    "        if self.net_type == 'ResNet-152':\n",
    "            print(\"Net_type is ResNet-152\")\n",
    "            layers = [3, 8, 36, 3]\n",
    "            \n",
    "        self.conv1 = torch.nn.Conv2d(3,64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1   = torch.nn.BatchNorm2d(64)\n",
    "        self.relu  = torch.nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.max_pooling = torch.nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True) \n",
    "        \n",
    "        self.layer1 = self._make_layer(BOT_block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(BOT_block, 128, layers[1])    \n",
    "        self.layer3 = self._make_layer(BOT_block, 256, layers[2])\n",
    "        self.layer4 = self._make_layer(TRI_block, 512, layers[3])\n",
    "        \n",
    "        \n",
    "        self.avg_pool = torch.nn.AvgPool2d(kernel_size=7) # размерность та же \n",
    "        self.FC = torch.nn.Linear(512 * BOT_block.expansion, num_classes)\n",
    "        \n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def res_forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.max_pooling(output)\n",
    "        \n",
    "        output = self.layer1(output)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        output = self.layer4(output)\n",
    "\n",
    "        # Вопрос - что  елать с выхоом после Tridnt bлока\n",
    "        output = torch.cat([output[0],output[1],output[2]], dim = 0)\n",
    "        return output\n",
    "    \n",
    "#----====----====----====----====----====----====----====----====----====----====----====----====----====----====\n",
    "    def _make_layer(self, block, output_channels, num_of_bottle_neck_blocks, stride = 1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.input_channels != output_channels*block.expansion:\n",
    "            downsample = torch.nn.Sequential(\n",
    "                                torch.nn.Conv2d(self.input_channels, output_channels * block.expansion,\n",
    "                                                kernel_size = 1, stride = stride, bias=False),\n",
    "                                torch.nn.BatchNorm2d(output_channels * block.expansion)\n",
    "            )\n",
    "        layers = list()\n",
    "        layers.append(block(self.input_channels, output_channels, downsample))\n",
    "        self.input_channels = output_channels * block.expansion\n",
    "        \n",
    "        for i in range(1,num_of_bottle_neck_blocks):\n",
    "            layers.append(block(self.input_channels,output_channels))\n",
    "            \n",
    "        return torch.nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/wllvcxz/faster-rcnn-pytorch/tree/master/model\n",
    "### https://github.com/jwyang/faster-rcnn.pytorch/blob/master/lib/model/rpn/rpn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!wget https://images.unsplash.com/photo-1458169495136-854e4c39548a -O girl_cars.jpg\n",
    "#object_detection_api('./girl_cars.jpg', rect_th=15, text_th=7, text_size=5, threshold=0.8)  \n",
    "img = cv2.imread('./girl_cars.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_img = torch.tensor(img).permute(2,0,1).unsqueeze(0)\n",
    "tensor_bbox = torch.tensor([2300,600, 3500, 3300], dtype = torch.float64)\n",
    "tensor_label = torch.tensor([1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pt1 = (2300,600) \n",
    "pt2 = (3500,3300)\n",
    "img2 = img.copy()\n",
    "for i in np.array(rez[0][:10]):\n",
    "    cv2.rectangle(img2, pt1,pt2, (255,0,0), thickness = 16)\n",
    "    cv2.rectangle(img2, (boxes[i][0],boxes[i][1]), (boxes[i][2],boxes[i][3]), color = (0,255,0), thickness = 16)\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "pt1 = (2300,600) \n",
    "pt2 = (3500,3300)\n",
    "pt = (pt1,pt2)\n",
    "bboxes = []\n",
    "img1 = img.copy()\n",
    "img1 = cv2.rectangle(img1, pt1,pt2, color = (255,0,0), thickness = 16)\n",
    "for proposals in range(100):\n",
    "    flag = random.choice([0,1])\n",
    "    if flag == 1:\n",
    "        x1 = pt[0][0]+random.randint(50, 500) \n",
    "        y1 = pt[0][1]+random.randint(50, 500)\n",
    "    else:\n",
    "        x1 = pt[0][0]-random.randint(50, 500) \n",
    "        y1 = pt[0][1]-random.randint(50, 500)\n",
    "\n",
    "    flag = random.choice([0,1])\n",
    "    if flag == 1:\n",
    "        x2 = pt[1][0]+random.randint(50, 500) \n",
    "        y2 = pt[1][1]+random.randint(50, 500)\n",
    "    else:    \n",
    "        x2 = pt[1][0]-random.randint(50, 500) \n",
    "        y2 = pt[1][1]-random.randint(50, 500)\n",
    "    \n",
    "    p11 = pt1\n",
    "    p12 = pt2\n",
    "    p21 = (x1,y1)\n",
    "    p22 = (x2,y2)\n",
    "    \n",
    "    xx1 = max(p11[0],p21[0])\n",
    "    yy1 = max(p11[1],p21[1])\n",
    "    xx2 = min(p12[0],p22[0])\n",
    "    yy2 = min(p12[1],p22[1])\n",
    "    w = xx2 - xx1\n",
    "    h = yy2 - yy1\n",
    "    square = w*h\n",
    "    union = (p12[0]-p11[0])*(p12[1]-p11[1]) + (p22[0]-p21[0])*(p22[1]-p21[1]) - square\n",
    "    iou = square/union    \n",
    "    \n",
    "    bboxes.append([[x1,y1, x2,y2], iou])\n",
    "    \n",
    "    cv2.rectangle(img1, (x1,y1), (x2,y2), color = (0,255,0), thickness = 16)\n",
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = []\n",
    "scores = []\n",
    "for el in bboxes:\n",
    "    boxes.append(el[0])\n",
    "    scores.append(el[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = torch.tensor(np.array(boxes), dtype = torch.float64)\n",
    "score = torch.tensor(np.array(scores), dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rez1 = torchvision.ops.nms(box, score, iou_threshold=0.5)\n",
    "rez1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
